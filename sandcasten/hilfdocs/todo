1) запустить spacy
2) выделяем entities в предложении --> entities в нужном формате

База для entities:
берут entities
берут pronouns
берут noun chunks

Они используют spacy (функция def generate_candidates(text) в run.py) --> нам нужно тоже использовать spacy, чтобы совпадали
Надо бы вытащить из spacy только тэги

Границы mention'ов
1) ищем entities: для них нужны оффсеты и ури; нужны лейблы тоже
2)



1) прогоняем документы
2) находим кандидатов с помощью spacy
3) выбираем предложения, которые подходят под паттерны Бена
4) совпадают ли аргументы по spacy типам
5) сохраняю предложения, информацию по нему (entities, relations, индекс на запись этого предложения в другой таблице),
    патерн предложения (объединить в матрицу, где столбцы - паттерны, строки - айди предложений, ячейки - 0/1)

Формат поиска свободный, можно индекс

2 варианта сборки датасета:
1) по паттернам
2) по паттернам + смотрим, какие были mentions встречались в этих предложениях --> эта пара аргументов = новый фильтр
    (--> увеличение датасета, bootstrapping в один шаг)


У Бена:
org:city_of_headquarters argtag GPE:CITY
org:city_of_headquarters enttype ORG
org:city_of_headquarters listtype false
А мы возьмем из: knowledge-net/baselines/EMNLP2019/instance.py

Самое главная информация: изначальный текст, какой паттерн, какой релейшн